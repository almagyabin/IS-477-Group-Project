# **PROJECT PLAN**

## **Overview**
Our Data Management, Curation, and Responsibility project will revolve around databases containing information on anime. Primarily, our data need is explore how popular the anime in the datasets are. We chose to focus on anime specifically because both of us are avid anime watchers and manga readers. Exploring a topic that we have a personal interest in adds an element of fun into an already interesting project. 
  
With our data need and research questions, we plan to develop a project that effectively implements the key topics and modules covered over the duration of this course, including but not limited to: *The Data Lifecycle* [Module One], *Data Collection and Acquisition* [Module Three], *Workflow Automation and Provenance* [Modules Eleven and Twelve] and *Metadata and Data Documentation* [Module Fifteen].

## **Research Questions**
Following up on the Overview section, our research questions are related to our data need. First, we want to ask: 	<ins>What is the most common rating given by users?</ins> We feel like this is an important question to investigate and answer because certain statistics [whether mean, mode, range] can give a general picture of the data and introduce insights and takeaways.

Secondly, we want to know: <ins>Does the rating of the show correlate with how many favorites it has?</ins> To us, this second research question will most likely require more analysis and supplementary visualizations, such as a scatter plot. Both questions can open the door to further examination, such as seeing if shows in similar genres share similar ratings and favorites or if shows with similar ratings debuted in the same year.

## **Team**
This team consists of two members, ***Alma Gyabin*** and ***Obi Obah***. Since there are only the two of us, it will be difficult to ‘assign roles’ as we will most likely be conducting the same research. Therefore, each team member [the both of us] will be responsible for meeting any timeline deadlines, as well as equally contributing to the project as much as possible. 
  
Furthermore, communication inside and outside the classroom is important in order to maintain a constant and efficient workflow. In addition to these basic responsibilities, each team member is responsible for the upkeep of the repository, which includes adding and cleaning files, committing changes, etc. In terms of actual work, each team member will be responsible for collecting data and answering one research question appropriately and according to the project guidelines.

## **Datasets**
The total amount of datasets and their specifics may change throughout the course of this project. If or when that happens, we will update this course project plan with any and all relevant details. The first dataset we will be using is called [**Anime Dataset 2025**](https://www.kaggle.com/datasets/rafidahmed816/anime-dataset-2025). According to Kaggle, *"this dataset contains information about various anime, including their titles, airing details, studios, genres, themes, and popularity metrics. It is useful for tasks like anime recommendation systems, trend analysis."* The dataset was posted by Rafid Ahmed, the only author and collaborator for the dataset. 

The second dataset we will use is also from Kaggle, titled [**Anime Database July 2025**](https://www.kaggle.com/datasets/sazzadsiddiquelikhon/myanimelist-anime-database-july-2025/data). According to the context provided on the website, *“this dataset represents a comprehensive snapshot of the MyAnimeList.net database as of July 16, 2025. It is designed to be a rich, clean, and accessible resource for data scientists, machine learning engineers, and anime enthusiasts. The data captures a wide array of information for over 28,000 unique anime titles, providing a deep look into the trends, metadata, and community ratings of the anime world.”* The dataset was posted by Md Sazzad Siddique, the only author and collaborator for the dataset.

## **Timeline**
Our project will run from Week 7 through Week 15, aligning with the course schedule and final deliverables. In Week 7, Alma and Obi will focus on integrating our two Kaggle datasets using Python and Pandas, making sure variables like ratings and favorites align properly. Alma will take the lead on dataset merging and initial exploratory data analysis, while Obi will handle data cleaning, removing duplicates, and addressing missing or inconsistent values. In Weeks 8 and 9, the team will assess data quality by checking for outliers, verifying accuracy, and documenting findings. By Week 10, Obi will begin setting up the structure for the automated workflow using Jupyter Notebook and GitHub, ensuring that all processes are traceable. Alma will work on visualizations, such as scatter plots and distribution graphs, to start answering the research questions. In Weeks 11 and 12, the team will refine the workflow automation and document provenance, ensuring reproducibility for anyone reviewing the work. During Weeks 13 and 14, they will focus on writing metadata and improving data documentation. Finally, in Week 15, they will finalize the report and presentation, making sure all analyses, code, and documentation are complete and consistent. Throughout the semester, Alma and Obi will meet weekly to review progress and update the repository together.

## **Constraints**
A major constraint for the project is time, especially since there are only two team members managing multiple technical tasks within a limited number of weeks. Alma and Obi will need to balance this project alongside other classwork, which makes careful scheduling essential. Another constraint is the potential for incomplete or inconsistent data in the Kaggle datasets. Missing ratings or mismatched formats between datasets could slow down the integration process or require manual adjustments. Technical constraints are also a concern, as some of the later modules involve skills, like workflow automation and provenance tracking, that the team is still developing. Additionally, since both datasets are created by third-party users, Alma and Obi must respect their licenses and ensure proper citation. There is also the challenge of making sure the analysis is fair and transparent, avoiding bias in how popularity and ratings are interpreted. Lastly, their limited experience with large dataset structures and automation tools could cause initial inefficiencies. To handle these constraints, Alma and Obi will divide responsibilities clearly, maintain weekly progress checks, and rely on instructor guidance and course materials as they strengthen their technical abilities.

## **Gaps**
While the team has a strong foundation for the project, there are still several gaps that they anticipate filling as the semester continues. One gap is their current understanding of workflow automation. Alma and Obi know that they will need to build a reproducible process, but they have yet to fully learn the best methods to automate data pipelines efficiently. Another gap involves metadata and documentation. They understand the importance of these for clarity and reusability, but they will rely on future modules to learn the proper standards and formats. The team also has a gap in determining how to structure long-term data storage so that the integrated datasets remain organized and accessible. Additionally, while their current research questions focus on ratings and favorites, they might identify new questions once they begin analyzing correlations or visualizing trends. A smaller gap lies in their current comfort level with SQL, which could enhance how they integrate or query data later on. These gaps are expected and part of the learning process. As Alma and Obi progress through future modules, gain more technical experience, and receive feedback, they will refine their approach to ensure the project grows stronger over time.
